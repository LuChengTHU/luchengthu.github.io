<html>

<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta name="description" content="Home page of Cheng Lu">
	<link rel="stylesheet" href="./files/jemdoc.css" type="text/css">
	<title>Cheng Lu</title>
</head>


<body>

<div id="layout-content" style="margin-top:25px">

<table><tbody><tr>
    <td width="670">
        <div id="toptitle"><h1>Cheng Lu (路橙)&nbsp;</h1></div>
        <h3>Research Scientist</h3>
        <h4>Meta Super Intelligence TBD Lab</h3>
        <br>
        <p>
            Email: <a href="mailto:lucheng.lc15@gmail.com">lucheng.lc15@gmail.com</a> <br>
            <a href="https://github.com/LuChengTHU">[Github]</a>
            <a href="https://scholar.google.com/citations?user=vPE9VRoAAAAJ">[Google Scholar]</a> 
            <a href="https://twitter.com/ChengLu05671218">[Twitter]</a> 
            <a href="https://luchengthu.github.io/files/chenglu_cv_en.pdf">[CV]</a> <br>
        </p>
    </td>

    <td><img src="./files/photo.jpg" border="0" width="200"></td>
</tr></tbody></table>


<h2>Biography</h2>
    <p> I am a research scientist at Meta Super Intelligence TBD Lab, working on pretraining architecture and optimization algorithms.</p>
    
    <p>I was a research scientist at OpenAI, where I was a core research contributor of <a href="https://openai.com/index/introducing-4o-image-generation/">GPT-4o Image Generation</a> and a research contributor of <a href="https://openai.com/index/sora-2">Sora 2</a>. I'm interested in large-scale deep generative models and reinforcement learning algorithms. I love to find a sweet balance between mathmetical theory and practical tricks. </p>
    
    <p> I received my Ph.D. degree from <a href="http://ml.cs.tsinghua.edu.cn/index.html">TSAIL Group</a> in December 2023 at <a href="https://www.tsinghua.edu.cn">Tsinghua University</a>, advised by <a href="http://ml.cs.tsinghua.edu.cn/~jun/">Prof. Jun Zhu</a>. During my Ph.D., I also worked closely with <a href="https://ml.cs.tsinghua.edu.cn/~jianfei/">Jianfei Chen</a> and <a href="https://zhenxuan00.github.io/">Chongxuan Li</a>. Before that, I received my B.E. degree from the Department of Computer Science and Technology, Tsinghua University in July, 2019.</p>

    <p>
        I had research experiences on consistency models, diffusion models, normalizing flows and energy-based models, and their applications in image generation, 3D generation and reinforcement learning.
    </p>

    <p>
        My Doctoral Dissertation (in Chinese): <a href="./files/chenglu_dissertation.pdf">Research on Invertible Generative Models and Efficient Algorithms</a>, supervised by <a href="http://ml.cs.tsinghua.edu.cn/~jun/">Prof. Jun Zhu</a>. 
    </p>


<h2>Research Highlight</h2>
<ul>
    <li>
        <a href='https://arxiv.org/abs/2410.11081'>Simplifying, Stabilizing and Scaling Continuous-Time Consistency Models</a> <br>
        <!-- <strong>Cheng Lu</strong>, Yang Song <br> -->
        <a href='https://openai.com/index/simplifying-stabilizing-and-scaling-continuous-time-consistency-models/'>[blog]</a> <br>
        <ul>
            <li>
                Continuous-time consistency models with sample quality comparable to leading diffusion models in just two sampling steps.
            </li>
        </ul>
    </li>
    <li>
        <a href='https://arxiv.org/abs/2305.16213'>ProlificDreamer & Variational Score Distillation</a> <br>
        <!-- Zhengyi Wang*, <strong>Cheng Lu*</strong>, Yikai Wang, Fan Bao, Chongxuan Li, Hang Su, Jun Zhu <br> -->
        <a href='https://github.com/thu-ml/prolificdreamer'>[code]</a>
        <a href='https://ml.cs.tsinghua.edu.cn/prolificdreamer/'>[project]</a> <br>
        <ul>
            <li>
                High-fidelity text-to-3D generation with solely 2D diffusion models.
            </li>
        </ul>
    </li>
    <li>
        <a href='https://arxiv.org/abs/2206.00927'>DPM-Solver</a>, <a href='https://arxiv.org/abs/2211.01095'>DPM-Solver++</a> and <a href='https://arxiv.org/abs/2310.13268'>DPM-Solver-v3</a> <br>
        <a href='https://github.com/LuChengTHU/dpm-solver'>[code]</a>
        <a href="https://huggingface.co/stabilityai/stable-diffusion-2-1#examples">[demo]</a> <br>
        <ul>
            <li>
                Training-free fast samplers for diffusion models (such as Stable Diffusion).
            </li>
            <li>
                Widely-applied in various of text-to-image libraries and applications, such as <a href="https://beta.dreamstudio.ai/home">DreamStudio</a>, <a href="https://stableboost.ai/">StableBoost</a>, <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui">Stable-Diffusion-WebUI</a>, <a href="https://github.com/huggingface/diffusers">Diffusers</a>, <a href="https://github.com/Stability-AI/stablediffusion">official Code of Stable Diffusion v2</a>, <a href="https://github.com/CompVis/stable-diffusion">official Code of Stable Diffusion v1</a>, <a href="https://huggingface.co/spaces/stabilityai/stable-diffusion">online demo of Stable Diffusion v2</a>, <a href="https://huggingface.co/spaces/runwayml/stable-diffusion-v1-5">online demo of Stable Diffusion v1.5</a>, <a href="https://github.com/apple/ml-stable-diffusion">Apple's ML-Stable-Diffusion</a>.
            </li>
        </ul>
        <!-- Corresponding papers: 
        <ul>
            <li>
                <a href='https://arxiv.org/abs/2206.00927'>DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps</a>. <br>
                <strong>Cheng Lu</strong>, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, Jun Zhu <br>
            </li>
            <li>
                <a href='https://arxiv.org/abs/2211.01095'>DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models</a> <br>
                <strong>Cheng Lu</strong>, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, Jun Zhu <br>
            </li>
            <li>
                <a href='https://arxiv.org/abs/2310.13268'>DPM-Solver-v3: Improved Diffusion ODE Solvers with Empirical Model Statistics</a> <br>
                Kaiwen Zheng*, <strong>Cheng Lu*</strong>, Jianfei Chen, Jun Zhu <br>
            </li>
        </ul> -->
    </li>
</ul>
<!-- * indicates co-first authors. -->

<h2>Publications</h2>
<ul>
    <li>
        <a href="https://arxiv.org/abs/2402.00856">Towards Efficient and Exact Optimization of Language Model Alignment</a> <br>
        Haozhe Ji, <strong>Cheng Lu</strong>, Yilin Niu, Pei Ke, Hongning Wang, Jun Zhu, Jie Tang, Minlie Huang <br>
        International Conference on Machine Learning <strong>(ICML)</strong>, 2024 <br>
        <a href='https://github.com/haozheji/exact-optimization'>[code]</a>
    </li>
    <li>
        <a href='https://arxiv.org/abs/2310.07297'>Score Regularized Policy Optimization through Diffusion Behavior</a> <br>
        Huayu Chen, <strong>Cheng Lu</strong>, Zhengyi Wang, Hang Su, Jun Zhu <br>
        International Conference on Learning Representations <strong>(ICLR)</strong>, 2024 <br>
        <a href='https://github.com/thu-ml/SRPO'>[code]</a>
    </li>
    <li>
        <a href='https://arxiv.org/abs/2311.01410'>The Blessing of Randomness: SDE Beats ODE in General Diffusion-based Image Editing</a> <br>
        Shen Nie, Hanzhong Allan Guo, <strong>Cheng Lu</strong>, Yuhao Zhou, Chenyu Zheng, Chongxuan Li <br>
        International Conference on Learning Representations <strong>(ICLR)</strong>, 2024 <br>
        <a href='https://github.com/ML-GSAI/SDE-Drag'>[code]</a>
        <a href='https://ml-gsai.github.io/SDE-Drag-demo/'>[project]</a>
    </li>
    <li>
        <a href='https://arxiv.org/abs/2305.16213'>ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation</a> <br>
        <font color="#FF0000">Spotlight</font> <br>
        Zhengyi Wang*, <strong>Cheng Lu*</strong>, Yikai Wang, Fan Bao, Chongxuan Li, Hang Su, Jun Zhu <br>
        Conference on Neural Information Processing Systems <strong>(NeurIPS)</strong>, 2023 <br>
        <a href='https://github.com/thu-ml/prolificdreamer'>[code]</a>
        <a href='https://ml.cs.tsinghua.edu.cn/prolificdreamer/'>[project]</a>
    </li>
    <li>
        <a href='https://arxiv.org/abs/2310.13268'>DPM-Solver-v3: Improved Diffusion ODE Solvers with Empirical Model Statistics</a> <br>
        Kaiwen Zheng*, <strong>Cheng Lu*</strong>, Jianfei Chen, Jun Zhu <br>
        Conference on Neural Information Processing Systems <strong>(NeurIPS)</strong>, 2023 <br>
        <a href='https://github.com/thu-ml/DPM-Solver-v3'>[code]</a>
        <a href='https://ml.cs.tsinghua.edu.cn/dpmv3/'>[project]</a>
    </li>
    <li>
        <a href='https://arxiv.org/abs/2302.10688'>On Calibrating Diffusion Probabilistic Models</a> <br>
        Tianyu Pang, <strong>Cheng Lu</strong>, Chao Du, Min Lin, Shuicheng YAN, Zhijie Deng <br>
        Conference on Neural Information Processing Systems <strong>(NeurIPS)</strong>, 2023 <br>
        <a href='https://github.com/thudzj/Calibrated-DPMs'>[code]</a>
    </li>
    <li>
        <a href='https://arxiv.org/abs/2311.00941'>Gaussian Mixture Solvers for Diffusion Models</a> <br>
        Hanzhong Allan Guo, <strong>Cheng Lu</strong>, Fan Bao, Tianyu Pang, Shuicheng YAN, Chao Du, Chongxuan Li <br>
        Conference on Neural Information Processing Systems <strong>(NeurIPS)</strong>, 2023 <br>
        <a href='https://github.com/guohanzhong/gms'>[code]</a>
    </li>
    <li>
        <a href='https://arxiv.org/abs/2305.03935'>Improved Techniques for Maximum Likelihood Estimation for Diffusion ODEs</a> <br>
        Kaiwen Zheng*, <strong>Cheng Lu*</strong>, Jianfei Chen, Jun Zhu <br>
        International Conference on Machine Learning <strong>(ICML)</strong>, 2023 <br>
        <a href='https://github.com/thu-ml/i-DODE'>[code]</a>
    </li>
    <li>
        <a href='https://arxiv.org/abs/2304.12824'>Contrastive Energy Prediction for Exact Energy-Guided Diffusion Sampling in Offline Reinforcement Learning</a> <br>
        <strong>Cheng Lu*</strong>, Huayu Chen*, Jianfei Chen, Hang Su, Chongxuan Li, Jun Zhu <br>
        International Conference on Machine Learning <strong>(ICML)</strong>, 2023 <br>
        <a href='https://github.com/ChenDRAG/CEP-energy-guided-diffusion'>[code]</a>
    </li>
    <li>
        <a href='https://arxiv.org/abs/2209.14548'>Offline Reinforcement Learning via High-Fidelity Generative Behavior Modeling</a> <br>
        Huayu Chen, <strong>Cheng Lu</strong>, Chengyang Ying, Hang Su, Jun Zhu <br>
        International Conference on Learning Representations <strong>(ICLR)</strong>, 2023 <br>
        <a href='https://github.com/ChenDRAG/SfBC'>[code]</a>
    </li>
    <li>
        <a href='https://arxiv.org/abs/2206.00927'>DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps</a> <br>
        <font color="#FF0000">Oral (Accept rate~1.7%)</font> <br>
        <strong>Cheng Lu</strong>, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, Jun Zhu <br>
        Conference on Neural Information Processing Systems <strong>(NeurIPS)</strong>, 2022 <br>
        <a href='https://github.com/LuChengTHU/dpm-solver'>[code]</a>
    </li>
    <li>
        <a href='https://arxiv.org/abs/2206.08265'>Maximum Likelihood Training for Score-Based Diffusion ODEs by High Order Denoising Score Matching</a> <br>
        <strong>Cheng Lu</strong>, Kaiwen Zheng, Fan Bao, Chongxuan Li, Jianfei Chen, Jun Zhu <br>
        International Conference on Machine Learning <strong>(ICML)</strong>, 2022 <br>
        <a href='https://github.com/LuChengTHU/mle_score_ode'>[code]</a>
    </li>
    <li>
        <a href='https://arxiv.org/abs/2103.09527'>Implicit Normalizing Flows</a> <br>
        <font color="#FF0000">Spotlight (Accept rate~5.5%)</font> <br>
        <strong>Cheng Lu</strong>, Jianfei Chen, Chongxuan Li, Qiuhao Wang, Jun Zhu.  <br>
        International Conference on Learning Representations <strong>(ICLR)</strong>, 2021 <br>
        <a href='https://github.com/thu-ml/implicit-normalizing-flows'>[code]</a>
    </li>
    <li>
        <a href='https://arxiv.org/abs/2002.09741'>VFlow: More Expressive Generative Flows with Variational Data Augmentation</a> <br>
        Jianfei Chen, <strong>Cheng Lu</strong>, Biqi Chenli, Jun Zhu, Tian Tian <br>
        International Conference on Machine Learning <strong>(ICML)</strong>, 2020 <br>
        <a href='https://github.com/thu-ml/vflow'>[code]</a>
    </li>
</ul>
* indicates co-first authors.

<h2>Preprints</h2>
<ul>
    <li>
        <a href='https://arxiv.org/abs/2410.11081'>Simplifying, Stabilizing and Scaling Continuous-Time Consistency Models</a> <br>
        <strong>Cheng Lu</strong>, Yang Song <br>
        <a href='https://openai.com/index/simplifying-stabilizing-and-scaling-continuous-time-consistency-models/'>[blog]</a> <br>
    </li>
    <li>
        <a href='https://arxiv.org/abs/2211.01095'>DPM-Solver++: Fast Solver for Guided Sampling of Diffusion Probabilistic Models</a> <br>
        <strong>Cheng Lu</strong>, Yuhao Zhou, Fan Bao, Jianfei Chen, Chongxuan Li, Jun Zhu <br>
        <a href='https://github.com/LuChengTHU/dpm-solver'>[code]</a> <br>
    </li>
</ul>

<h2>Selected Honors & Awards</h2>
<ul>
    <li>
        <strong>
            Outstanding Doctoral Thesis, Tsinghua University
        </strong>, 2024.06
    </li>
    <li>
        <strong>
            <a href="https://jw.beijing.gov.cn/tzgg/202401/t20240102_3522508.html">Beijing Outstanding Graduates</a>
        </strong>, 2024.01
    </li>
    <li>
        <strong>
            <a href="https://www.cs.tsinghua.edu.cn/info/1088/5784.htm">Zhong Shimo Scholarship</a>
        </strong>, 2023.12
    </li>
    <li>
        <strong>
            <a href="https://www.cs.tsinghua.edu.cn/info/1088/5784.htm">China National Scholarship</a>
        </strong>, 2023.12
    </li>
    <li>
        <strong>
            <a href="https://ur.bytedance.com/scholarship">ByteDance Scholarship</a>
        </strong>, 2023.10
    </li>
    <li>
        <strong>'84' Future Innovation Scholarship, Tsinghua University</strong>, 2020.12
    </li>
    <li>
        <strong>Top Ten Compus Singers Competition, Tsinghua University</strong>, 2019.10
    </li>
    <li>
        <strong>Outstanding Graduates, Department of Computer Science and Technology, Tsinghua University</strong>, 2019.06
    </li>
    <li>
        <strong>The Mathematical Contest in Modeling, Meritorious Winner</strong>, 2018
    </li>
    <li>
        <strong>Chinese Mathematical Olympiad (CMO), Silver Medal</strong>, 2014
    </li>
</ul>


<h2>Services</h2>
<h3>Reviewer</h3>
    <strong>NeurIPS</strong> (2021, 2022 with <strong><a href="https://neurips.cc/Conferences/2022/ProgramCommittee">Top Reviewer</a></strong>, <a href="https://score-based-methods-workshop.github.io/">2022 workshop</a>); <strong>ICML</strong> (2021-2024); <strong>ICLR</strong> (2021, 2023-2024); <strong>CVPR</strong> (2023-2024); <strong>ICCV</strong> 2023; <strong>ECCV</strong> 2024; <strong>IJCV</strong>;

<h3> Contributor</h3>
    <strong><a href="https://github.com/huggingface/diffusers">huggingface/diffusers</a></strong>, the most widely-used library for diffusion models.


<h3>Teaching</h3>
2021 Spring, Head TA in <strong>Statistical Learning Theory and Applications</strong>, instructed by <a href="http://ml.cs.tsinghua.edu.cn/~jun/">Prof. Jun Zhu</a><br>
2021 Spring, TA in <strong>Deep Learning</strong>, instructed by <a href="http://www.xlhu.cn/">Prof. Xiaolin Hu</a> and <a href="http://ml.cs.tsinghua.edu.cn/~jun/">Prof. Jun Zhu</a><br>

<h2>Personal</h2>
I was a bass singer in Chorus of Tsinghua University. I won the top ten compus singers competition of Tsinghua University in 2019 by singing a famous jazz song <i>Autumn Leaves</i>. I love singing!

</div>

<div id="footer">
	<div id="footer-text"></div>
</div>
&copy 2024 Cheng Lu

</body>

</html>
